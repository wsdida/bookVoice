# audiobook_generator.py (æ·»åŠ æ£€æŸ¥ç°æœ‰wavæ–‡ä»¶åŠŸèƒ½)
import os
import logging
from pathlib import Path

import yaml
import torch
import whisper
import json
import re
import jiwer
import jieba
from ollama import Client
from TTS.api import TTS
from pydub import AudioSegment
import sys
import glob
from config.database import DatabaseManager

db_manager = DatabaseManager()
# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["COQUI_TOS_AGREED"] = "1"
# å…¨å±€å®¢æˆ·ç«¯åˆå§‹åŒ–
ollama_client = Client()


# --- æ—¥å¿—é…ç½®å‡½æ•° ---
def setup_logger(output_dir):
    log_dir = os.path.join(output_dir, 'logs')
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, 'audiobook.log')
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—å·²é…ç½®åˆ°: {log_file}")
    return logger


def load_config(config_path='config.yaml'):
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        raise


def normalize_text(text):
    if not isinstance(text, str):
        return ""
    text = re.sub(r'\W+', ' ', text).lower()
    return text.strip()


def chinese_tokenizer(text):
    return list(jieba.cut(text))


def extract_chapters(input_file, output_dir):
    chapters_dir = os.path.join(output_dir, 'chapters')
    os.makedirs(chapters_dir, exist_ok=True)

    content = None
    encodings_to_try = ['utf-8', 'gbk', 'gb18030', 'latin1', 'cp1252']
    for enc in encodings_to_try:
        try:
            with open(input_file, 'r', encoding=enc) as f:
                content = f.read()
            print(f"æˆåŠŸä½¿ç”¨ç¼–ç  '{enc}' è¯»å–æ–‡ä»¶: {input_file}")
            break
        except UnicodeDecodeError:
            continue
        except Exception as e:
            print(f"ä½¿ç”¨ç¼–ç  '{enc}' è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿå…¶ä»–é”™è¯¯: {e}")
            continue

    if content is None:
        print(f"è­¦å‘Šï¼šæ— æ³•ä½¿ç”¨æ ‡å‡†ç¼–ç è¯»å–æ–‡ä»¶ {input_file}ã€‚å°†ä½¿ç”¨ 'utf-8' ç¼–ç å¹¶æ›¿æ¢é”™è¯¯å­—ç¬¦ã€‚")
        with open(input_file, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()

    chapter_pattern = r'(?P<title>(?:Chapter\s+\d+|CHAPTER\s+[IVXLC]+|ç¬¬[\s\S]{1,9}?ç« |åºç« |å¼•å­|å°¾å£°|åè®°))'
    matches = list(re.finditer(chapter_pattern, content, flags=re.IGNORECASE))
    chapter_files = []
    toc = []
    if not matches:
        print(f"è­¦å‘Š: åœ¨ {input_file} ä¸­æœªæ£€æµ‹åˆ°ç« èŠ‚æ ‡é¢˜ï¼Œå°†æ•´ä¸ªæ–‡ä»¶ä½œä¸ºä¸€ç« å¤„ç†")
        chapter_file = os.path.join(chapters_dir, 'chapter_01.txt')
        with open(chapter_file, 'w', encoding='utf-8') as f:
            f.write(content)
        toc.append({"chapter": 1, "title": "å…¨æ–‡", "file": chapter_file})
        chapter_files.append(chapter_file)
    else:
        for i in range(len(matches)):
            start = matches[i].start()
            end = matches[i + 1].start() if i + 1 < len(matches) else len(content)
            chapter_title = matches[i].group('title').strip()
            chapter_text = content[start:end].strip()
            chapter_file = os.path.join(chapters_dir, f'chapter_{i + 1:02d}.txt')
            with open(chapter_file, 'w', encoding='utf-8') as f:
                f.write(chapter_text)
            toc.append({"chapter": i + 1, "title": chapter_title, "file": chapter_file})
            chapter_files.append(chapter_file)
    with open(os.path.join(output_dir, 'toc.json'), 'w', encoding='utf-8') as f:
        json.dump(toc, f, ensure_ascii=False, indent=2)
    print(f"ç« èŠ‚åˆ†å‰²å®Œæˆï¼Œå…± {len(chapter_files)} ä¸ªç« èŠ‚")
    return chapter_files


def clean_ollama_response(response_text):
    if not isinstance(response_text, str):
        return response_text
    cleaned_text = re.sub(r'<THINK>.*?</THINK>', '', response_text, flags=re.DOTALL | re.IGNORECASE)
    cleaned_text = re.sub(r'\n\s*\n', '\n', cleaned_text)
    cleaned_text = cleaned_text.strip()
    return cleaned_text


def analyze_chapter(text):
    try:
        prompt = f"""You are a novel analysis assistant. Please carefully read the following novel text and annotate it based on the original text:
Requirements:
1.  Preserve all content and formatting of the original text.
2.  Add a marker before dialogue: [Character Name|Emotion], for example: [Zhang San|joy]"Hello!"
3.  Add a marker before narrative paragraphs: [Narration|Emotion], for example: [Narration|neutral]Night fell.
4.  Emotion categories are limited to: joy, anger, fear, sadness, surprise, neutral.
5.  Do not change the original text content, only add markers.
6.  Every paragraph or sentence must be annotated.
7.  Maintain the original line breaks and paragraph structure.
8.  Return only the annotated text, do not add any explanations or notes.
9.  Do not use <THINK> tags or any other thought process indicators.
The text is as follows:
{text}
Please return the fully annotated text.
"""
        messages = [
            {"role": "system",
             "content": "You are a novel text annotation expert. Please strictly add markers to the original text according to the format, and do not use <THINK> tags."},
            {"role": "user", "content": prompt}
        ]
        response = ollama_client.chat(model="mistral:7b", messages=messages)
        annotated_text = response["message"]["content"]
        annotated_text = clean_ollama_response(annotated_text)
        return annotated_text
    except Exception as e:
        print(f"ç« èŠ‚åˆ†æå¤±è´¥: {str(e)}")
        return f"[å™è¿°|neutral]{text}"


def parse_annotated_text(annotated_text):
    try:
        annotations = []
        lines = annotated_text.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
            pattern = r'\[([^|\]]+)\|([^\]]+)\](.*)'
            match = re.match(pattern, line)
            if match:
                speaker_or_type = match.group(1)
                emotion = match.group(2)
                content = match.group(3).strip()
                if speaker_or_type == "å™è¿°":
                    anno_type = "narration"
                    speaker = "Narrator"
                else:
                    anno_type = "dialogue"
                    speaker = speaker_or_type
                annotations.append({
                    "type": anno_type,
                    "speaker": speaker,
                    "text": content,
                    "emotion": emotion.lower()
                })
            else:
                if line.strip():
                    annotations.append({
                        "type": "narration",
                        "speaker": "Narrator",
                        "text": line,
                        "emotion": "neutral"
                    })
        return annotations
    except Exception as e:
        print(f"è§£ææ ‡æ³¨æ–‡æœ¬å¤±è´¥: {str(e)}")
        return []


def annotate_text(chapters, output_dir):
    try:
        annotations_dir = os.path.join(output_dir, 'annotations')
        os.makedirs(annotations_dir, exist_ok=True)
        annotations = {}
        for chapter_file in chapters:
            with open(chapter_file, 'r', encoding='utf-8') as f:
                text = f.read()
            chapter_num = os.path.basename(chapter_file).split('.')[0]
            print(f"åˆ†æç« èŠ‚ï¼š{chapter_num}")
            annotated_text = analyze_chapter(text)
            annotated_file = os.path.join(annotations_dir, f'{chapter_num}_annotated.txt')
            with open(annotated_file, 'w', encoding='utf-8') as f:
                f.write(annotated_text)
            result = parse_annotated_text(annotated_text)
            anno_file = os.path.join(annotations_dir, f'{chapter_num}.json')
            with open(anno_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            annotations[chapter_num] = result
        print("æ–‡æœ¬æ ‡æ³¨å®Œæˆ")
        return annotations
    except Exception as e:
        print(f"æ–‡æœ¬æ ‡æ³¨å¤±è´¥: {str(e)}")
        raise


def check_transcription(audio_file, original_text, whisper_model, threshold=0.1):
    try:
        if not os.path.exists(audio_file) or os.path.getsize(audio_file) == 0:
            return False, float('inf')
        result = whisper_model.transcribe(audio_file, language="en")
        transcribed_text = result["text"]
        original_clean = normalize_text(original_text)
        transcribed_clean = normalize_text(transcribed_text)
        if not original_clean or not transcribed_clean:
            return True, 0.0
        wer = jiwer.wer(original_clean, transcribed_clean)
        return wer <= threshold, wer
    except Exception as e:
        print(f"è½¬å½•å¤±è´¥ {audio_file}: {str(e)}")
        return False, float('inf')


def create_speaker_mapper(tts, role_to_speaker):
    available_speakers = list(tts.synthesizer.tts_model.speaker_manager.speakers.keys())
    print(f"å¯ç”¨çš„ speakers: {available_speakers}")
    speaker_mapping_cache = {}

    def get_valid_speaker(role_name):
        if role_name in speaker_mapping_cache:
            return speaker_mapping_cache[role_name]
        requested_speaker = role_to_speaker.get(role_name, role_to_speaker.get("Narrator", available_speakers[
            0] if available_speakers else "default"))
        if requested_speaker in available_speakers:
            speaker_mapping_cache[role_name] = requested_speaker
            return requested_speaker
        fallback_speaker = available_speakers[0] if available_speakers else "default"
        print(f"è­¦å‘Š: è§’è‰² '{requested_speaker}' ä¸å­˜åœ¨ï¼Œæ˜ å°„åˆ° '{fallback_speaker}'")
        speaker_mapping_cache[role_name] = fallback_speaker
        return fallback_speaker

    return get_valid_speaker


def synthesize_tts(chapter_file, annotations, role_to_speaker, output_dir, tts, whisper_model, threshold=0.1,
                   force_rebuild=False):
    try:
        get_valid_speaker = create_speaker_mapper(tts, role_to_speaker)
        chapter_num = os.path.basename(chapter_file).split('.')[0]
        print(f"å¼€å§‹åˆæˆç« èŠ‚: {chapter_num}")

        chapter_audio_dir = os.path.join(output_dir, 'chapters')
        os.makedirs(chapter_audio_dir, exist_ok=True)

        for i, anno in enumerate(annotations):
            text = anno.get('text', '')
            role = anno.get('speaker', 'Narrator')
            if not text.strip():
                print(f"è­¦å‘Š: ç« èŠ‚ {chapter_num} ç¬¬ {i} æ®µæ–‡æœ¬ä¸ºç©ºï¼Œè·³è¿‡")
                continue

            speaker = get_valid_speaker(role)
            # ä¿æŒç°æœ‰æ ¼å¼ï¼šä½¿ç”¨å®é™…çš„speakeråç§°ä½œä¸ºè§’è‰²å
            safe_speaker_name = re.sub(r'[\\/:*?"<>|]', '_', speaker)
            output_file = os.path.join(chapter_audio_dir, f'{chapter_num}_{safe_speaker_name}_{i:03d}.wav')

            if os.path.exists(output_file) and not force_rebuild:
                if os.path.getsize(output_file) > 0:
                    print(f"âœ… è·³è¿‡å·²å­˜åœ¨çš„è¯­éŸ³æ–‡ä»¶: {output_file}")
                    continue

            if force_rebuild and os.path.exists(output_file):
                try:
                    os.remove(output_file)
                    print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§è¯­éŸ³æ–‡ä»¶: {output_file}")
                except OSError as e:
                    print(f"âš ï¸ åˆ é™¤æ–‡ä»¶å¤±è´¥ {output_file}: {e}")

            try:
                tts.tts_to_file(text=text, speaker=speaker, language="en", file_path=output_file)
                print(f"ğŸ”Š åˆæˆå®Œæˆ: {output_file}")
            except Exception as e:
                print(f"TTS åˆæˆå¤±è´¥ {output_file}: {str(e)}")
                continue

            is_ok, wer = check_transcription(output_file, text, whisper_model, threshold)
            if not is_ok:
                print(f"âš ï¸ è½¬å½•ä¸åŒ¹é… {output_file}, WER: {wer:.3f}")
            else:
                print(f"âœ… æ ¡éªŒé€šè¿‡ {output_file}, WER: {wer:.3f}")

        print(f"âœ… ç« èŠ‚ {chapter_num} TTS åˆæˆå®Œæˆ")
    except Exception as e:
        print(f"TTS åˆæˆè¿‡ç¨‹å‡ºé”™: {str(e)}")
        raise


def find_existing_wav_files(chapter_audio_dir, chapter_formatted):
    """
    æŸ¥æ‰¾æŒ‡å®šç« èŠ‚çš„æ‰€æœ‰wavæ–‡ä»¶
    è¿”å›æŒ‰åºå·æ’åºçš„æ–‡ä»¶åˆ—è¡¨
    """
    # æŸ¥æ‰¾è¯¥ç« èŠ‚çš„æ‰€æœ‰wavæ–‡ä»¶
    pattern = os.path.join(chapter_audio_dir, f'{chapter_formatted}_*_[0-9][0-9][0-9].wav')
    wav_files = glob.glob(pattern)

    # æŒ‰åºå·æ’åº
    wav_files.sort(
        key=lambda x: int(re.search(r'_([0-9]{3})\.wav$', x).group(1)) if re.search(r'_([0-9]{3})\.wav$', x) else 0)

    return wav_files


def mix_audio(annotations, output_dir, effect_dir, role_to_speaker=None, force_rebuild=False):
    try:
        print("å¼€å§‹éŸ³æ•ˆæ··éŸ³")
        chapter_audio_dir = os.path.join(output_dir, 'chapters')
        os.makedirs(chapter_audio_dir, exist_ok=True)

        # å¦‚æœrole_to_speakeræœªæä¾›ï¼Œåˆ›å»ºé»˜è®¤æ˜ å°„
        if role_to_speaker is None:
            role_to_speaker = {"Narrator": "default"}

        for chapter_key, anno_list in annotations.items():
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç« èŠ‚ç¼–å·æ ¼å¼
            # å¦‚æœchapter_keyæ˜¯"chapter_01"è¿™æ ·çš„æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
            # å¦åˆ™éœ€è¦æå–æ•°å­—å¹¶æ ¼å¼åŒ–
            if chapter_key.startswith('chapter_'):
                chapter_formatted = chapter_key
            else:
                # å°è¯•ä»chapter_keyä¸­æå–æ•°å­—
                match = re.search(r'(\d+)', chapter_key)
                if match:
                    chapter_number = int(match.group(1))
                    chapter_formatted = f'chapter_{chapter_number:02d}'
                else:
                    chapter_formatted = chapter_key

            final_output_file = os.path.join(chapter_audio_dir, f'{chapter_formatted}_final.mp3')

            if os.path.exists(final_output_file) and not force_rebuild:
                if os.path.getsize(final_output_file) > 0:
                    print(f"âœ… è·³è¿‡å·²å­˜åœ¨çš„æœ€ç»ˆéŸ³é¢‘: {final_output_file}")
                    continue

            if force_rebuild and os.path.exists(final_output_file):
                try:
                    os.remove(final_output_file)
                    print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§æœ€ç»ˆéŸ³é¢‘: {final_output_file}")
                except OSError as e:
                    print(f"âš ï¸ åˆ é™¤æœ€ç»ˆéŸ³é¢‘å¤±è´¥ {final_output_file}: {e}")

            print(f"æ··éŸ³ç« èŠ‚: {chapter_formatted}")

            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨wavæ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™ç›´æ¥ä½¿ç”¨
            existing_wav_files = find_existing_wav_files(chapter_audio_dir, chapter_formatted)
            if existing_wav_files :
                print(f"  -> å‘ç° {len(existing_wav_files)} ä¸ªå·²å­˜åœ¨çš„wavæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨")
                chapter_audio = AudioSegment.silent(duration=0)

                for wav_file in existing_wav_files:
                    if os.path.exists(wav_file) and os.path.getsize(wav_file) > 0:
                        try:
                            audio = AudioSegment.from_wav(wav_file)
                            chapter_audio += audio + AudioSegment.silent(duration=200)
                            print(f"  -> å·²æ·»åŠ : {os.path.basename(wav_file)}")
                        except Exception as e:
                            print(f"  -> åŠ è½½éŸ³é¢‘å¤±è´¥ {wav_file}: {str(e)}")
                            continue
                    else:
                        print(f"  -> è·³è¿‡æ— æ•ˆæ–‡ä»¶: {wav_file}")
            else:
                # å¦‚æœæ²¡æœ‰ç°æœ‰wavæ–‡ä»¶ï¼Œåˆ™æŒ‰åŸæœ‰é€»è¾‘ç”Ÿæˆ
                print(f"  -> æœªå‘ç°ç°æœ‰wavæ–‡ä»¶ï¼ŒæŒ‰åŸæœ‰é€»è¾‘ç”Ÿæˆ")
                chapter_audio = AudioSegment.silent(duration=0)

                for i, anno in enumerate(anno_list):
                    # ä¿æŒç°æœ‰æ ¼å¼ï¼šä½¿ç”¨å®é™…çš„speakeråç§°ä½œä¸ºè§’è‰²å
                    role = anno.get('speaker', 'Narrator')
                    speaker = role_to_speaker.get(role, role_to_speaker.get("Narrator", "default"))
                    safe_speaker_name = re.sub(r'[\\/:*?"<>|]', '_', speaker)
                    audio_file = os.path.join(chapter_audio_dir, f'{chapter_formatted}_{safe_speaker_name}_{i:03d}.wav')
                    if not os.path.exists(audio_file):
                        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {audio_file}")
                        continue
                    try:
                        audio = AudioSegment.from_wav(audio_file)
                        chapter_audio += audio + AudioSegment.silent(duration=200)
                    except Exception as e:
                        print(f"åŠ è½½éŸ³é¢‘å¤±è´¥ {audio_file}: {str(e)}")
                        continue

            if len(chapter_audio) == 0:
                print(f"âš ï¸ ç« èŠ‚ {chapter_formatted} æ— æœ‰æ•ˆéŸ³é¢‘æ•°æ®ï¼Œè·³è¿‡å¯¼å‡º")
                continue

            bg_added = False
            effect_file = os.path.join(effect_dir, 'background.wav')
            if not os.path.exists(effect_file):
                for fallback in ['forest.wav', 'ambient.wav', 'music.wav']:
                    fallback_file = os.path.join(effect_dir, fallback)
                    if os.path.exists(fallback_file):
                        effect_file = fallback_file
                        break
            if os.path.exists(effect_file):
                try:
                    bg_audio = AudioSegment.from_wav(effect_file) - 15
                    chapter_audio = chapter_audio.overlay(bg_audio, loop=True)
                    bg_added = True
                except Exception as e:
                    print(f"åŠ è½½èƒŒæ™¯éŸ³æ•ˆå¤±è´¥ {effect_file}: {str(e)}")

            if not bg_added:
                print("ğŸŸ¡ æœªæ·»åŠ èƒŒæ™¯éŸ³æ•ˆ")

            try:
                chapter_audio.export(final_output_file, format='mp3', bitrate='192k')
                print(f"âœ… æ··éŸ³å®Œæˆ: {final_output_file}")
            except Exception as e:
                print(f"âŒ å¯¼å‡ºéŸ³é¢‘å¤±è´¥ {final_output_file}: {str(e)}")

        print("âœ… éŸ³æ•ˆæ··éŸ³å®Œæˆ")
    except Exception as e:
        print(f"âŒ éŸ³æ•ˆæ··éŸ³è¿‡ç¨‹å‡ºé”™: {str(e)}")
        raise


def get_chapter_status(output_dir, chapter_num):
    """æ£€æŸ¥ç« èŠ‚æ˜¯å¦å·²ç»å®Œæˆç”Ÿæˆ"""
    chapters_dir = os.path.join(output_dir, 'chapters')
    # ç¡®ä¿chapter_numæ ¼å¼æ­£ç¡®
    if not chapter_num.startswith('chapter_'):
        # å¦‚æœä¼ å…¥çš„æ˜¯æ•°å­—ï¼Œæ ¼å¼åŒ–ä¸ºæ­£ç¡®çš„æ ¼å¼
        if isinstance(chapter_num, int) or chapter_num.isdigit():
            chapter_num = f'chapter_{int(chapter_num):02d}'
        else:
            # å¦‚æœchapter_numæ˜¯ç±»ä¼¼"01"çš„å­—ç¬¦ä¸²ï¼Œæ·»åŠ å‰ç¼€
            match = re.match(r'^(\d+)', chapter_num)
            if match:
                chapter_num = f'chapter_{int(match.group(1)):02d}'

    final_file = os.path.join(chapters_dir, f'{chapter_num}_final.mp3')
    return os.path.exists(final_file) and os.path.getsize(final_file) > 0


def find_last_completed_chapter(output_dir, total_chapters):
    """æŸ¥æ‰¾æœ€åä¸€ä¸ªå®Œæˆçš„ç« èŠ‚"""
    for i in range(total_chapters, 0, -1):
        chapter_num = f'chapter_{i:02d}'
        if get_chapter_status(output_dir, chapter_num):
            return i
    return 0

def generate_audiobook(input_directory, input_file_path, config_path='config.yaml', force_rebuild=False, auto_update_rss=True):
    try:
        base_output_dir = os.path.dirname(input_file_path)
        story_title = os.path.splitext(os.path.basename(input_file_path))[0]
        output_dir = os.path.join(base_output_dir, f"{story_title}_audiobook_output")
        os.makedirs(output_dir, exist_ok=True)

        logger = setup_logger(output_dir)
        print(f"=== å¼€å§‹ç”Ÿæˆæœ‰å£°ä¹¦: {story_title} ===")
        logger.info(f"=== å¼€å§‹ç”Ÿæˆæœ‰å£°ä¹¦: {story_title} ===")

        config = load_config(config_path)
        config['input_file'] = input_file_path
        config['output_dir'] = output_dir

        device = "cuda" if torch.cuda.is_available() else "cpu"
        tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2").to(device)
        whisper_model = whisper.load_model(config.get('whisper_model', 'base'))

        chapters = extract_chapters(config['input_file'], config['output_dir'])

        # æ–­ç‚¹ç»­ä¼ é€»è¾‘ - åŸºäºæ•°æ®åº“çŠ¶æ€
        start_index = 0
        if not force_rebuild:
            # ä»æ•°æ®åº“è·å–æœªå¤„ç†çš„éŸ³é¢‘ç« èŠ‚
            unprocessed_chapters = db_manager.get_unprocessed_audio_chapters(story_title)
            if unprocessed_chapters:
                # æ‰¾åˆ°æœ€å°çš„æœªå¤„ç†ç« èŠ‚ç¼–å·
                start_index = min(unprocessed_chapters) - 1  # è½¬æ¢ä¸º0ç´¢å¼•
                print(f"æ ¹æ®æ•°æ®åº“çŠ¶æ€ï¼Œä»ç¬¬ {start_index + 1} ä¸ªç« èŠ‚å¼€å§‹ç”Ÿæˆ")
            else:
                # æ£€æŸ¥æœ¬åœ°æ–‡ä»¶çŠ¶æ€ä½œä¸ºåå¤‡
                last_completed = find_last_completed_chapter(output_dir, len(chapters))
                if last_completed > 0:
                    print(f"æ£€æµ‹åˆ°å‰ {last_completed} ä¸ªç« èŠ‚å·²ç”Ÿæˆï¼Œä»ç¬¬ {last_completed + 1} ä¸ªç« èŠ‚å¼€å§‹ç”Ÿæˆ")
                    start_index = last_completed
                else:
                    print("ä»ç¬¬ä¸€ä¸ªç« èŠ‚å¼€å§‹ç”Ÿæˆ")

        # å¦‚æœä¸æ˜¯å¼ºåˆ¶é‡å»ºä¸”æ‰€æœ‰ç« èŠ‚éƒ½å·²å®Œæˆï¼Œåˆ™è·³è¿‡
        if not force_rebuild and start_index >= len(chapters):
            print("æ‰€æœ‰ç« èŠ‚å‡å·²ç”Ÿæˆå®Œæˆï¼Œæ— éœ€é‡å¤ç”Ÿæˆ")
            return

        # åªå¯¹éœ€è¦ç”Ÿæˆçš„ç« èŠ‚è¿›è¡Œå¤„ç†
        chapters_to_process = chapters[start_index:]

        # å¦‚æœéœ€è¦é‡æ–°å¤„ç†æ³¨é‡Šï¼ˆå› ä¸ºå¯èƒ½éœ€è¦å…¨éƒ¨ç« èŠ‚çš„æ³¨é‡Šï¼‰
        annotations = annotate_text(chapters, config['output_dir'])

        all_speakers = {"Narrator"}
        for anno_list in annotations.values():
            for anno in anno_list:
                if anno.get('type') == 'dialogue' and anno.get('speaker'):
                    all_speakers.add(anno['speaker'])
        available_speakers = list(tts.synthesizer.tts_model.speaker_manager.speakers.keys())
        role_to_speaker = {
            "Narrator": config.get('narrator_speaker', available_speakers[0] if available_speakers else "default"),
            "Unknown": config.get('narrator_speaker', available_speakers[0] if available_speakers else "default")
        }
        speaker_index = 0
        for speaker in all_speakers:
            if speaker not in role_to_speaker:
                role_to_speaker[speaker] = available_speakers[speaker_index % len(available_speakers)]
                speaker_index += 1

        # åªå¤„ç†éœ€è¦ç”Ÿæˆçš„ç« èŠ‚
        for i, (chapter_file, anno_list) in enumerate(
                zip(chapters_to_process, list(annotations.values())[start_index:])):
            actual_index = start_index + i
            chapter_num = f'chapter_{actual_index + 1:02d}'
            print(f"å¼€å§‹å¤„ç†ç« èŠ‚ {actual_index + 1}/{len(chapters)}: {chapter_num}")

            # æ£€æŸ¥æ•°æ®åº“ä¸­çš„ç« èŠ‚çŠ¶æ€
            if not force_rebuild:
                db_chapter_status = db_manager.get_unprocessed_audio_chapters(story_title)
                if (actual_index + 1) not in db_chapter_status and get_chapter_status(output_dir, chapter_num):
                    print(f"ç« èŠ‚ {chapter_num} å·²åœ¨æ•°æ®åº“ä¸­æ ‡è®°ä¸ºå®Œæˆä¸”æ–‡ä»¶å­˜åœ¨ï¼Œè·³è¿‡")
                    continue

            synthesize_tts(chapter_file, anno_list, role_to_speaker, config['output_dir'], tts, whisper_model,
                           config.get('whisper_threshold', 0.1), force_rebuild=force_rebuild)

            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            db_manager.update_chapter_audio_status(story_title, actual_index + 1, 'completed')

        # æ··éŸ³å¤„ç†ä¹Ÿå¯ä»¥æ·»åŠ æ–­ç‚¹é€»è¾‘
        annotations_subset = dict(list(annotations.items())[start_index:])
        mix_audio(annotations_subset, config['output_dir'], config.get('effect_dir', 'effects'),
                  role_to_speaker, force_rebuild=force_rebuild)

        manifest = {
            "chapters": [
                {
                    "chapter": i + 1,
                    "file": f"chapter_{i + 1:02d}_final.mp3",
                    "speakers": list(set(anno.get('speaker', 'Narrator') for anno in anno_list))
                }
                for i, anno_list in enumerate(annotations.values())
            ]
        }
        with open(os.path.join(config['output_dir'], 'manifest.json'), 'w', encoding='utf-8') as f:
            json.dump(manifest, f, ensure_ascii=False, indent=2)
        print("âœ… å…ƒæ•°æ®ç”Ÿæˆå®Œæˆ")
        logger.info("âœ… å…ƒæ•°æ®ç”Ÿæˆå®Œæˆ"+input_directory)

        # å°†åŸæ¥çš„ RSS æ›´æ–°ä»£ç æ›¿æ¢ä¸º:
        if auto_update_rss:
            try:
                from generate_and_deploy_rss import run_rss_update_process
                run_rss_update_process(input_directory)
                print("âœ… RSS æ›´æ–°å®Œæˆ")
            except Exception as rss_error:
                print(f"âŒ è°ƒç”¨ RSS æ›´æ–°è„šæœ¬æ—¶å‡ºé”™: {rss_error}")
                logger.error(f"âŒ è°ƒç”¨ RSS æ›´æ–°è„šæœ¬æ—¶å‡ºé”™: {rss_error}")
        else:
            print("â­ï¸ è·³è¿‡è‡ªåŠ¨ RSS æ›´æ–°ï¼Œç”±ä¸»æ§åˆ¶å™¨å¤„ç†")

        print(f"âœ… === æœ‰å£°ä¹¦ç”Ÿæˆå®Œæˆ: {story_title} ===")
        logger.info(f"âœ… === æœ‰å£°ä¹¦ç”Ÿæˆå®Œæˆ: {story_title} ===")

    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        raise
